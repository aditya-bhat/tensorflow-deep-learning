{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKarSre47Ahv"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number.\n",
        "\n",
        "See full course materials on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u8MsQmV7hDo",
        "outputId": "6625b989-212d-425e-bbfb-809553dda586"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IalXU1QB7spg"
      },
      "source": [
        "## Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YQZbzH4O70xl",
        "outputId": "5fb93606-ea25-49d2-e629-9a087a64e400"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clux4ncl8TJ8",
        "outputId": "51860c4c-a0c3-44c2-efeb-a08c1d2333a3"
      },
      "source": [
        "y == X + 10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWmKUOWc8mdz"
      },
      "source": [
        "## Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmEIIElh8x1Z",
        "outputId": "956610ce-8dab-4792-bf53-e326b9034ffb"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DExhPoos9gZF",
        "outputId": "e5ee9381-f3bd-4957-b557-189d38dc8524"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq-Pb-Z69jxp",
        "outputId": "935c0107-d012-49d3-bd8d-d7a6e907a9f8"
      },
      "source": [
        "X[1], y[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-20V_X69OE0",
        "outputId": "be327950-a5e3-4944-83e6-cfb88ee41f3c"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaOI4HU19bBJ",
        "outputId": "39d5d3aa-6fa5-485c-9166-0ad1d43b4d0b"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYHpBCXQ93xD",
        "outputId": "d27501cd-7940-4a85-87e0-c60a218ad7aa"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXXzG3aR97i7",
        "outputId": "95cf88b9-9156-42a0-8b86-c6321b7abf8b"
      },
      "source": [
        "# Turn our NumPy arrays into tensors with dtype float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTUb3n6d_FrY",
        "outputId": "0b5dd7e2-605b-4785-bb43-f5b6e82a5ca8"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "NUB3rlwu_OZ5",
        "outputId": "989f507c-d148-4e71-eaf1-8019872718b1"
      },
      "source": [
        "plt.scatter(X, y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fb0109965d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu0RYMXr_VC-"
      },
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss funtion (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. Fitting a model - letting the model try to find patterns between X & y (features and labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9k5wWQe_aU3",
        "outputId": "3fd5277f-9f4c-499a-e31a-105408c8ffec"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochasitc gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb01464cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOkNe41hChw-",
        "outputId": "1b4ee514-3cee-4c2f-a035-d1de26cd7f88"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JBE5S-4DQFj",
        "outputId": "350e9be1-24d4-43ce-a35e-a06ea8d8aee0"
      },
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZm0x_e0DdvS",
        "outputId": "97de0c95-3bf8-49e0-b4bd-a25f24c3c7b3"
      },
      "source": [
        "y_pred + 11"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RIo2cOiDrHC"
      },
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hideen layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki4x75jCDwlu",
        "outputId": "aa19d622-f477-479e-9bfa-6c47592eac77"
      },
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb00d98bfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMa-jMl6ccRT",
        "outputId": "b6aa1804-03a1-4dcf-fa56-c91d5ec67b7a"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_w1g_ZKc0K_",
        "outputId": "008c2d27-12b8-4e8d-c845-a5eed1de88fe"
      },
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8r7_kLzc932",
        "outputId": "84f7bfd0-117c-474d-fb77-135bbb100c87"
      },
      "source": [
        "# Let's see if we can make another to improve our model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=None),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs=100) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 12.0109 - mae: 12.0109\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.0827 - mae: 11.0827\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.1377 - mae: 10.1377\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1687 - mae: 9.1687\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1666 - mae: 8.1666\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1234 - mae: 7.1234\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0477 - mae: 7.0477\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4551 - mae: 7.4551\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7955 - mae: 7.7955\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.8032 - mae: 7.8032\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5199 - mae: 7.5199\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1109 - mae: 7.1109\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7677 - mae: 6.7677\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4015 - mae: 6.4015\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2357 - mae: 6.2357\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2423 - mae: 6.2423\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3558 - mae: 6.3558\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3170 - mae: 6.3170\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1485 - mae: 6.1485\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8645 - mae: 5.8645\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6410 - mae: 5.6410\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4964 - mae: 5.4964\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.4790 - mae: 5.4790\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4653 - mae: 5.4653\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.3918 - mae: 5.3918\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2633 - mae: 5.2633\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0845 - mae: 5.0845\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8603 - mae: 4.8603\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5949 - mae: 4.5949\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4549 - mae: 4.4549\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3419 - mae: 4.3419\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2469 - mae: 4.2469\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9892 - mae: 3.9892\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7639 - mae: 3.7639\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5838 - mae: 3.5838\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4578 - mae: 3.4578\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2638 - mae: 3.2638\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0042 - mae: 3.0042\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6811 - mae: 2.6811\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4239 - mae: 2.4239\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3193 - mae: 2.3193\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0514 - mae: 2.0514\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5789 - mae: 1.5789\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2803 - mae: 1.2803\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0003 - mae: 1.0003\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6312 - mae: 0.6312\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3519 - mae: 0.3519\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3731 - mae: 0.3731\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5498 - mae: 0.5498\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7918 - mae: 0.7918\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8574 - mae: 0.8574\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9624 - mae: 0.9624\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9383 - mae: 0.9383\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9712 - mae: 0.9712\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8290 - mae: 0.8290\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7937 - mae: 0.7937\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6822 - mae: 0.6822\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3600 - mae: 0.3600\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3560 - mae: 0.3560\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - mae: 0.4129\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2622 - mae: 0.2622\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5552 - mae: 0.5552\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6130 - mae: 0.6130\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4665 - mae: 0.4665\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5549 - mae: 0.5549\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5040 - mae: 0.5040\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3059 - mae: 0.3059\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3180 - mae: 0.3180\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1289 - mae: 0.1289\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3193 - mae: 0.3193\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4343 - mae: 0.4343\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3293 - mae: 0.3293\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5476 - mae: 0.5476\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6088 - mae: 0.6088\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3411 - mae: 0.3411\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4043 - mae: 0.4043\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6183 - mae: 0.6183\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4809 - mae: 0.4809\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0982 - mae: 0.0982\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2504 - mae: 0.2504\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1929 - mae: 0.1929\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1561 - mae: 0.1561\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0545 - mae: 0.0545\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3572 - mae: 0.3572\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3705 - mae: 0.3705\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0835 - mae: 0.0835\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3945 - mae: 0.3945\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4196 - mae: 0.4196\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1171 - mae: 0.1171\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4845 - mae: 0.4845\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6957 - mae: 0.6957\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5739 - mae: 0.5739\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1783 - mae: 0.1783\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4492 - mae: 0.4492\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6536 - mae: 0.6536\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5370 - mae: 0.5370\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1539 - mae: 0.1539\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4828 - mae: 0.4828\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - mae: 0.6920\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5813 - mae: 0.5813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb00c083990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAkq8adjeo2y",
        "outputId": "6223425c-36af-46b6-f36c-84ca91213632"
      },
      "source": [
        "# Let's remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Wym6W6e45i",
        "outputId": "921dfa59-5d35-4360-936e-1c981b77791d"
      },
      "source": [
        "# Let's try to make a prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.485754]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYOVI6lMe_KR"
      },
      "source": [
        "## Evaluting a model\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model  -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usrqoYOojh5S"
      },
      "source": [
        "When it comes to evaluation... there are 3 words you should memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zcYJzAykVku",
        "outputId": "1674eac9-1fdf-4f22-d922-b4e23df703b8"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYmBjJyGkyhf",
        "outputId": "3d3b8ab0-df59-4565-9c76-4d30d3acfabb"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GsPCWn6Bk7-n",
        "outputId": "6ae49c7d-45bb-4df6-d8fe-3bb42758bd83"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fb00c8d3dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVC0lEQVR4nO3df+xldX3n8edr8UeItQuWWToOTGdwgV1MswN8w5qgJgoWIa2Api5s4uJqOjUr2brdpR1k05htTFGWmjRtdIeUFDcquuWHpKWLIG672yzWGWc6DALLDIXI13EYdRGzEir43j++54t3xnvnO9/vPffXuc9HcnPP/Zx773nPuZf3nHndD+ekqpAkddM/mHQBkqTRsclLUofZ5CWpw2zyktRhNnlJ6rCXTbqAXieddFJt2rRp0mVI0kzZuXPnd6pqXb91U9XkN23axI4dOyZdhiTNlCRPDlpnXCNJHWaTl6QOs8lLUofZ5CWpw2zyktRhUzW7RpLmzZ27Frnhnkf51jPP8doTjueai87ksrM3tPb+NnlJmpA7dy1y7e0P8tyPXgRg8ZnnuPb2BwFaa/TGNZI0ITfc8+hLDX7Zcz96kRvuebS1bdjkJWlCvvXMc6saXwvjGkkag37Z+2tPOJ7FPg39tScc39p2PZKXpBFbzt4Xn3mO4ifZ+1v+yTqOf/lxhz33+JcfxzUXndnatlfV5JPcnOTpJHt7xl6T5N4kjzX3JzbjSfIHSfYl2ZPknNaqlqQZMih7/8ojh/i9d/4iG044ngAbTjie33vnL050ds2fAH8IfLpnbBvw5aq6Psm25vFvAxcDpze3fw58srmXpLlytOz9srM3tNrUj7SqI/mq+ivge0cMXwrc0izfAlzWM/7pWvIAcEKS9cMUK0nT7M5di5x//f1s3vbnnH/9/dy5axEYnLG3mb0P0kYmf3JVHWiWvw2c3CxvAL7Z87ynmrHDJNmaZEeSHYcOHWqhHEkav0G5+527FrnmojNHnr0P0uoPr1VVQK3yNduraqGqFtat63vOe0maekeb837Z2RtGnr0P0sYUyoNJ1lfVgSaOeboZXwRO7XneKc2YJHXOSnPeR529D9JGk78LuAq4vrn/Ys/41UluZekH1+/3xDqSNLMmNed9LVY7hfJzwP8GzkzyVJL3s9Tc35bkMeDC5jHA3cDjwD7gJuDftFa1JE3IJOe8r8WqjuSr6soBqy7o89wCPriWoiRpWq00532UZ5RcC09rIEmrMMk572thk5ekAWYpex/Ec9dIUh+zlr0PYpOXpD4meb6ZNhnXSFIfs5a9D2KTlzT3upC9D2JcI2mudSV7H8QmL2mudSV7H8S4RtJc60r2PohNXtLc6HL2PohxjaS50PXsfRCbvKS50PXsfRDjGklzoevZ+yA2eUmd0i93v+zsDZ3P3gcxrpHUGdN6ndVJsslL6oxpvc7qJA0d1yQ5E/h8z9BpwO8AJwC/Bhxqxj9cVXcPuz1JGmRar7M6SUMfyVfVo1W1paq2AOcCPwTuaFZ/YnmdDV7SqA3K17ueux9N2z+8XgDsr6onk7T81pL0E/1+YL3mojO59vYHD4ts5iF3P5q2M/krgM/1PL46yZ4kNyc5seVtSZpTg35gBeYydz+aLF1vu4U3Sl4BfAt4fVUdTHIy8B2ggN8F1lfV+/q8biuwFWDjxo3nPvnkk63UI6m7zr/+/r7TITeccDx/ve2tE6hospLsrKqFfuvaPJK/GPh6VR0EqKqDVfViVf0YuAk4r9+Lqmp7VS1U1cK6detaLEdSV630A6t+os1M/kp6opok66vqQPPwcmBvi9uSNCfm8aRibWrlSD7Jq4C3Abf3DH88yYNJ9gBvAf5dG9uSND/m9aRibWrlSL6q/h/wc0eMvaeN95Y0v1Y6qVi/0xfocJ67RtLUmteTirXJJi9pKpi9j4bnrpE0cWbvo2OTlzRx83pBj3EwrpE0cWbvo2OTlzRWZu/jZVwjaWzM3sfPJi9pbMzex8+4RtLYmL2Pn01eUuu8mPb0MK6R1Covpj1dbPKSWuXFtKeLcY2kVnkx7elik5e0Zs55n37GNZLWxDnvs8EmL2lNnPM+G4xrJK2Jc95nQ2tNPskTwA+AF4EXqmohyWuAzwObgCeAd1fV/21rm5LGw+x9drUd17ylqrZU1ULzeBvw5ao6Hfhy81jSDDF7n22jzuQvBW5plm8BLhvx9iS1zOx9trWZyRfwpSQF/Jeq2g6cXFUHmvXfBk4+8kVJtgJbATZu3NhiOZLaYPY+29ps8m+sqsUk/wi4N8kjvSurqpq/ADhifDuwHWBhYeGn1ksaH7P37mktrqmqxeb+aeAO4DzgYJL1AM39021tT1K7zN67qZUmn+RVSV69vAz8ErAXuAu4qnnaVcAX29iepPaZvXdTW3HNycAdSZbf87NV9d+TfA34QpL3A08C725pe5JaZvbeTa00+ap6HPhnfca/C1zQxjYktcfsfX54WgNpzpi9zxebvDRnzN7ni+eukeaM2ft8sclLHeV1VgXGNVIneZ1VLbPJSx3kdVa1zLhG6iCvs6plNnlpxjnnXUdjXCPNMOe8ayU2eWmGOeddKzGukWaYc961Epu8NCPM3rUWxjXSDDB711rZ5KUZYPautTKukWaA2bvWyiYvTRmzd7Vp6LgmyalJvpLkG0keSvIbzfhHkiwm2d3cLhm+XKnbzN7VtjYy+ReAf19VZwFvAD6Y5Kxm3Seqaktzu7uFbUmdZvautg0d11TVAeBAs/yDJA8DfvOkNTB7V9tanV2TZBNwNvDVZujqJHuS3JzkxAGv2ZpkR5Idhw4darMcaWrduWuR86+/n83b/pzzr7+fO3ctAoMzdrN3rVVrTT7JzwC3AR+qqmeBTwKvA7awdKR/Y7/XVdX2qlqoqoV169a1VY40tTzXu8aplSaf5OUsNfjPVNXtAFV1sKperKofAzcB57WxLWnWea53jdPQmXySAH8MPFxVv98zvr7J6wEuB/YOuy2pCzzXu8apjXny5wPvAR5MsrsZ+zBwZZItQAFPAL/ewrakmeKcd01aG7Nr/heQPqucMqm5tpy9L0czy9n7u87dwG07Fw+LbMzdNSqeu0YaEee8axp4WgNpRJzzrmlgk5daYPauaWVcIw3J881omtnkpSGZvWuaGddIQzJ71zSzyUurYPauWWNcIx0js3fNIpu8dIzM3jWLjGukY2T2rllkk5f6MHtXVxjXSEcwe1eX2OSlI5i9q0uMa6QjmL2rS2zymlv9cvfLzt5g9q5OMa7RXPI6q5oXI2/ySd6e5NEk+5JsG/X2pGPhdVY1L0Ya1yQ5Dvgj4G3AU8DXktxVVd8Y5XallXidVc2LUWfy5wH7qupxgCS3ApcCNnmNjXPeNc9GHddsAL7Z8/ipZuwlSbYm2ZFkx6FDh0ZcjuaNc9417yb+w2tVba+qhapaWLdu3aTLUcc4513zbtRxzSJwas/jU5oxaSyc8655N+om/zXg9CSbWWruVwD/csTb1Jwye5d+2kjjmqp6AbgauAd4GPhCVT00ym1qPpm9S/2NPJOvqrur6oyqel1VfXTU29N8MnuX+vO0BuoEs3epP5u8Zo7Zu3TsJj6FUloNs3dpdWzymilm79LqGNdoppi9S6tjk9fUMnuXhmdco6lk9i61wyavqWT2LrXDuEZTyexdaodNXhPldVal0TKu0cR4nVVp9GzymhivsyqNnnGNJsbrrEqjZ5PXWDjnXZoM4xqNnHPepcmxyWvknPMuTc5QcU2SG4BfAf4e2A/866p6Jskmlq4E9Wjz1Aeq6gPDbEuzyznv0uQMm8nfC1xbVS8k+RhwLfDbzbr9VbVlyPfXjDF7l6bLUHFNVX2puY4rwAPAKcOXpFll9i5NnzYz+fcBf9HzeHOSXUn+MsmbBr0oydYkO5LsOHToUIvlaNzM3qXps2Jck+Q+4Of7rLquqr7YPOc64AXgM826A8DGqvpuknOBO5O8vqqePfJNqmo7sB1gYWGh1vbH0DQwe5emz4pNvqouPNr6JO8Ffhm4oKqqec3zwPPN8s4k+4EzgB3DFqzpYPYuzYah4pokbwd+C3hHVf2wZ3xdkuOa5dOA04HHh9mWpofZuzQ7hs3k/xB4NXBvkt1JPtWMvxnYk2Q38KfAB6rqe0NuS1PC7F2aHUNNoayqfzxg/DbgtmHeW9PL7F2aHZ67Rkdl9i7NNk9roIHM3qXZZ5PXQGbv0uwzrtFAZu/S7LPJy+usSh1mXDPnvM6q1G02+TnndValbjOumXNeZ1XqNo/k59ygfN3cXeoGj+TnSL8fWK+56Eyuvf3BwyIbc3epOzySnxODfmAFzN2lDvNIfk4c7QfWv972Vpu61FEeyc+JlX5gldRNHsl3kCcVk7TMI/mO8aRiknrZ5DvGk4pJ6jVUXJPkI8CvAYeaoQ9X1d3NumuB9wMvAv+2qu4ZZls6Np5UTFKvNjL5T1TVf+4dSHIWcAXweuC1wH1JzqiqF/u9gdbG7F3SSkYV11wK3FpVz1fV3wH7gPNGtK25ZPYu6Vi00eSvTrInyc1JTmzGNgDf7HnOU82YWmL2LulYrBjXJLkP+Pk+q64DPgn8LlDN/Y3A+1ZTQJKtwFaAjRs3rualc83sXdKxWLHJV9WFx/JGSW4C/qx5uAic2rP6lGas3/tvB7YDLCws1LFsa554QQ9Jwxgqrkmyvufh5cDeZvku4Iokr0yyGTgd+JthtjWPvKCHpGENO7vm40m2sBTXPAH8OkBVPZTkC8A3gBeADzqzZvVWOt/M8nOOPMqXpGVDNfmqes9R1n0U+Ogw7z/vvKCHpGF57pop4Zx3SaPgaQ2mgHPeJY2KTX4KOOdd0qgY10wB57xLGhWb/JiZvUsaJ+OaMTJ7lzRuNvkxMnuXNG7GNWNk9i5p3GzyI2L2LmkaGNeMgNm7pGlhkx8Bs3dJ08K4ZgTM3iVNC5v8kMzeJU0z45ohmL1LmnY2+SGYvUuadsY1QzB7lzTtbPLHwOusSppVw17j9fNJdje3J5LsbsY3JXmuZ92n2il3/LzOqqRZNuzl//7F8nKSG4Hv96zeX1Vbhnn/aeB1ViXNslbimiQB3g28tY33myZeZ1XSLGsrk38TcLCqHusZ25xkF/As8B+r6n/2e2GSrcBWgI0bN7ZUzto4511S16yYySe5L8nePrdLe552JfC5nscHgI1VdTbwm8Bnk/xsv/evqu1VtVBVC+vWrRvmzzIU57xL6qIVj+Sr6sKjrU/yMuCdwLk9r3keeL5Z3plkP3AGsGOoakdopTnv5u6SZlEbcc2FwCNV9dTyQJJ1wPeq6sUkpwGnA4+3sK2Rcc67pC5qo8lfweFRDcCbgf+U5EfAj4EPVNX3WthWK8zeJc2LoZt8Vb23z9htwG3DvvcoLGfvy9HMcvb+rnM3cNvOxcMiG7N3SbNu7s5d4/lmJM2TuTutgdm7pHnS6SZv9i5p3nU2rnHeuyR1uMmbvUtSh+Mas3dJ6kiTN3uXpP5mPq4xe5ekwWa+yZu9S9JgMx/XmL1L0mAzfyQ/KGM3e5ekDjR5r7MqSYPNfFyzHMd4vndJ+mkz3+TB66xK0iAzH9dIkgazyUtSh9nkJanDbPKS1GE2eUnqsFTVpGt4SZJDwJNDvMVJwHdaKqdN01oXWNtaWdvqTWtdMPu1/UJVreu3Yqqa/LCS7KiqhUnXcaRprQusba2sbfWmtS7odm3GNZLUYTZ5SeqwrjX57ZMuYIBprQusba2sbfWmtS7ocG2dyuQlSYfr2pG8JKmHTV6SOmwmm3ySX03yUJIfJ1k4Yt21SfYleTTJRT3jb2/G9iXZNqY6P59kd3N7IsnuZnxTkud61n1qHPUcUdtHkiz21HBJz7q++3CMtd2Q5JEke5LckeSEZnwa9tvYv0dHqeXUJF9J8o3mv4ffaMYHfrZjru+JJA82Nexoxl6T5N4kjzX3J06grjN79s3uJM8m+dCk9luSm5M8nWRvz1jf/ZQlf9B8//YkOWfFDVTVzN2AfwqcCfwPYKFn/Czgb4FXApuB/cBxzW0/cBrwiuY5Z4255huB32mWNwF7J7wPPwL8hz7jfffhmGv7JeBlzfLHgI9Nw36bhu/REfWsB85pll8N/J/m8+v72U6gvieAk44Y+ziwrVnetvzZTvgz/TbwC5Pab8CbgXN6v9uD9hNwCfAXQIA3AF9d6f1n8ki+qh6uqkf7rLoUuLWqnq+qvwP2Aec1t31V9XhV/T1wa/PcsUgS4N3A58a1zSEM2odjU1VfqqoXmocPAKeMc/tHMdHv0ZGq6kBVfb1Z/gHwMDDtF1a4FLilWb4FuGyCtQBcAOyvqmH+T/uhVNVfAd87YnjQfroU+HQteQA4Icn6o73/TDb5o9gAfLPn8VPN2KDxcXkTcLCqHusZ25xkV5K/TPKmMdbS6+rmn3w39/yzedL76kjvY+nIZdkk99u07ZuXJNkEnA18tRnq99mOWwFfSrIzydZm7OSqOtAsfxs4eTKlveQKDj/4mob9BoP306q/g1Pb5JPcl2Rvn9vEjpz6OcY6r+TwL9IBYGNVnQ38JvDZJD875to+CbwO2NLUc2Pb2x+ituXnXAe8AHymGRrLfps1SX4GuA34UFU9y4Q/2x5vrKpzgIuBDyZ5c+/KWsofJjaHO8krgHcA/60Zmpb9dphh99PUXv6vqi5cw8sWgVN7Hp/SjHGU8aGsVGeSlwHvBM7tec3zwPPN8s4k+4EzgB1t1HSstfXUeBPwZ83Do+3D1hzDfnsv8MvABc2XfGz77SjGsm9WI8nLWWrwn6mq2wGq6mDP+t7PdqyqarG5fzrJHSzFXQeTrK+qA03M8PQkamtcDHx9eX9Ny35rDNpPq/4OTu2R/BrdBVyR5JVJNgOnA38DfA04Pcnm5m/vK5rnjsOFwCNV9dTyQJJ1SY5rlk9r6nx8TPUs19Cb410OLP+yP2gfjrO2twO/Bbyjqn7YMz7p/TbJ79FPaX7r+WPg4ar6/Z7xQZ/tOGt7VZJXLy+z9GP6Xpb211XN064Cvjju2noc9i/sadhvPQbtp7uAf9XMsnkD8P2eWKe/Sf6yPcSv0ZezlEU9DxwE7ulZdx1LMyAeBS7uGb+EpdkH+4HrxljrnwAfOGLsXcBDwG7g68CvTGAf/lfgQWBP88VZv9I+HGNt+1jKHXc3t09N0X6byPdoQC1vZOmf8Xt69tUlR/tsx1jbaSzNPvrb5jO7rhn/OeDLwGPAfcBrJrTvXgV8F/iHPWMT2W8s/UVzAPhR09feP2g/sTSr5o+a79+D9MwuHHTztAaS1GFdi2skST1s8pLUYTZ5Seowm7wkdZhNXpI6zCYvSR1mk5ekDvv/Gg0+q3BJ5t4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYSYiP6mlE-g"
      },
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6x4ayTkmbsz",
        "outputId": "71c77c6a-a8f8-4f58-97f8-9e41119bbaa4"
      },
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSFQQTirmyvV",
        "outputId": "a66d6ebd-9bad-4219-e9bb-2a505f135c48"
      },
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data) \n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TppBKDWnbKC"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and test sets... let's visualize it again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Wx8g6vh9nwLs",
        "outputId": "f81cf5b0-866c-4c8b-f698-2d7bc1078070"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\") # our model will learn on this\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\") # want our model to be able to predict this (given X, what's y?)\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0U3nhHtpKve"
      },
      "source": [
        "# Let's have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)                             \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# # 3. Fit the model\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnscI3h_qP5a"
      },
      "source": [
        "### Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "gfiOkjp5qSiZ",
        "outputId": "d026a22a-2381-459c-ddf6-8126d8806cc6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \"\"\"\n\u001b[1;32m   2375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2377\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2QjQhzq6Ah",
        "outputId": "4c0ed453-51f6-4068-94dc-92e92f31d536"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzPTRyrCqVpT"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument in the first layer\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1, name=\"output_layer\")\n",
        "], name=\"model_1\")\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RDh-9PdrMXo",
        "outputId": "9b631c34-3435-47c4-d506-0183742f14ba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8BlRom8rhQx"
      },
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learn patterns or parameters from other models during **transfer learning**).\n",
        "\n",
        " **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out [MIT's introduction to deep learning video](https://youtu.be/njKP3FqW3Sk). \n",
        "\n",
        " **Exercise:** Try playing around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP91lGTgrPno",
        "outputId": "487d83eb-edab-419a-b07d-8d520d9a3c38"
      },
      "source": [
        "# Let's fit our model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb00adf4050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS4oIHfktlex",
        "outputId": "45bafacd-9051-4f5b-da8b-ad32cc7dd061"
      },
      "source": [
        "# Get a summary of our model\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "--yP4uW8ugKH",
        "outputId": "c791c408-22fe-4b3c-9d41-4b3ce9437fb5"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORwPibL8u7Yk"
      },
      "source": [
        "### Visualizing our model's predictions\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model's predictions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85dQbIrHsggD",
        "outputId": "d1900309-4789-482e-dcdb-b92d3d0a88cc"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw7TyglVtUZL",
        "outputId": "899b0023-a2f7-4483-ff56-230375d08bfb"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZvNFJGVtjov"
      },
      "source": [
        " **Note:** If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJsnIciYtWfn"
      },
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth labels.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot model's predictions in red\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "6VeRueShuhfN",
        "outputId": "c7fcd1cd-0e62-40fc-dc3f-302669e12c28"
      },
      "source": [
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poOuTGosukJU"
      },
      "source": [
        "### Evaluting our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "Since we're working on a regression, two of the main metrics: \n",
        "* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions\"\n",
        "* MSE - mean square error, \"square the average errors\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmeohFOJu_C_",
        "outputId": "37a27ab8-6a65-4df9-eaab-49755e1d6075"
      },
      "source": [
        "# Evaluate the model on the test\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 138ms/step - loss: 3.1969 - mae: 3.1969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.1969428062438965, 3.1969428062438965]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWAP6TCJyUeL",
        "outputId": "71a6c1ce-12d9-42d3-b57c-68230ab53807"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, \n",
        "                                     y_pred=tf.constant(y_pred))\n",
        "mae"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znxoDzBCyGEd",
        "outputId": "0d1babbe-ad66-495c-b592-1572de9ce866"
      },
      "source": [
        "tf.constant(y_pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB5OwjD2ySv4",
        "outputId": "387215c5-7c8b-4c04-c74b-a347e726ea15"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fit8MiNSyTZu",
        "outputId": "633ac7f0-4c17-4f3d-aae5-6df1d8c73c29"
      },
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
              "        93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFhtsK8J1j2M",
        "outputId": "827fc7e3-0c26-4532-8a60-5d3b3917f5fd"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))\n",
        "mae"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK4bRMgi4LcR",
        "outputId": "e5a765ad-5c70-4f4c-c626-0ee25faac40e"
      },
      "source": [
        "# Calculate the mean square error\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                    y_pred=tf.squeeze(y_pred))\n",
        "mse"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46VZYQ28tFP"
      },
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                        y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4mlm41z9w6S"
      },
      "source": [
        "## Running experiments to improve our model\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it ...\n",
        "```\n",
        "\n",
        "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
        "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. Train for longer - give your model more of a chance to find patterns in the data.\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "3. `model_3` - 2 layers, trained for 500 epochs \n",
        "\n",
        "**Build `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cLyuLdP-SIw",
        "outputId": "c8075025-9ad9-4635-b52b-48e7c0b1d02a"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4124 - mae: 16.4124\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0829 - mae: 11.0829\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1242 - mae: 11.1242\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6945 - mae: 8.6945\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.8003 - mae: 9.8003\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5263 - mae: 9.5263\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4102 - mae: 8.4102\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1449 - mae: 9.1449\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.4932 - mae: 19.4932\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6061 - mae: 9.6061\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5992 - mae: 8.5992\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9324 - mae: 10.9324\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0574 - mae: 10.0574\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.5679 - mae: 16.5679\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4537 - mae: 11.4537\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4056 - mae: 8.4056\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.8417 - mae: 13.8417\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6621 - mae: 11.6621\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.7623 - mae: 18.7623\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.5702 - mae: 15.5702\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.9959 - mae: 10.9959\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0023 - mae: 8.0023\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8593 - mae: 9.8593\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5796 - mae: 7.5796\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7226 - mae: 13.7226\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.1740 - mae: 17.1740\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4233 - mae: 13.4233\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.5473 - mae: 14.5473\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.8753 - mae: 9.8753\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1187 - mae: 17.1187\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.5949 - mae: 24.5949\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6765 - mae: 7.6765\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2971 - mae: 9.2971\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.1703 - mae: 14.1703\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8635 - mae: 10.8635\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.5689 - mae: 13.5689\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3448 - mae: 9.3448\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4804 - mae: 10.4804\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0178 - mae: 10.0178\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8005 - mae: 10.8005\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7789 - mae: 7.7789\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2844 - mae: 10.2844\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.9628 - mae: 8.9628\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6243 - mae: 12.6243\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1236 - mae: 14.1236\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.2681 - mae: 8.2681\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0126 - mae: 9.0126\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6882 - mae: 10.6882\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7431 - mae: 7.7431\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3950 - mae: 9.3950\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9267 - mae: 8.9267\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9818 - mae: 16.9818\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.8677 - mae: 14.8677\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.0413 - mae: 22.0413\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.0640 - mae: 17.0640\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9520 - mae: 9.9520\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7522 - mae: 9.7522\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4378 - mae: 9.4378\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3373 - mae: 8.3373\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6425 - mae: 9.6425\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7590 - mae: 11.7590\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7187 - mae: 11.7187\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2316 - mae: 7.2316\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7848 - mae: 17.7848\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6255 - mae: 12.6255\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2840 - mae: 13.2840\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8471 - mae: 7.8471\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9708 - mae: 9.9708\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4903 - mae: 12.4903\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5001 - mae: 8.5001\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9996 - mae: 9.9996\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1797 - mae: 10.1797\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0024 - mae: 13.0024\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3812 - mae: 10.3812\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7621 - mae: 9.7621\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5186 - mae: 11.5186\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3070 - mae: 8.3070\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4436 - mae: 9.4436\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.3897 - mae: 20.3897\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4751 - mae: 15.4751\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0208 - mae: 9.0208\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3869 - mae: 13.3869\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9649 - mae: 7.9649\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.5702 - mae: 7.5702\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9706 - mae: 9.9706\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0533 - mae: 9.0533\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2670 - mae: 12.2670\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1986 - mae: 7.1986\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0379 - mae: 13.0379\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1968 - mae: 7.1968\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5386 - mae: 7.5386\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0932 - mae: 7.0932\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.8860 - mae: 12.8860\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9620 - mae: 9.9620\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7739 - mae: 8.7739\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0861 - mae: 13.0861\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3848 - mae: 8.3848\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7828 - mae: 9.7828\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5252 - mae: 8.5252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb01000c210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9Wfj4dqK-z6H",
        "outputId": "514d16d8-8a0a-43cc-ab5b-aec13938d78c"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb00f6b4e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B2ujgQeALRb",
        "outputId": "bffe4186-6e69-4f72-c662-dfe705b76ae4"
      },
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "mae_1, mse_1"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMKAg48cAcAX"
      },
      "source": [
        "**Build `model_2`**\n",
        "\n",
        "* 2 dense layers, trained for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfNxa4oOBK55",
        "outputId": "9d36abc3-ea1f-40c3-8204-cb772efcac78"
      },
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.8627 - mse: 1015.8976\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.4175 - mse: 767.5334\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 31.5187 - mse: 1433.3081\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 27.8490 - mse: 1141.6671\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6465 - mse: 267.4541\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.9682 - mse: 169.5529\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0874 - mse: 141.6589\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3978 - mse: 167.3422\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 42.4087 - mse: 2772.5432\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.3537 - mse: 1129.8181\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6590 - mse: 132.9751\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.8820 - mse: 933.4347\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.7682 - mse: 398.1734\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.6019 - mse: 1102.2358\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7361 - mse: 441.0350\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4550 - mse: 81.2729\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6974 - mse: 163.8851\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.7691 - mse: 610.4133\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6535 - mse: 146.6566\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.4600 - mse: 487.0986\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.2352 - mse: 362.8490\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.5012 - mse: 290.6680\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6493 - mse: 88.0710\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4430 - mse: 131.0228\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.8060 - mse: 237.9437\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.8011 - mse: 1075.4349\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0333 - mse: 202.1001\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.4573 - mse: 871.2026\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1266 - mse: 92.4710\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.1804 - mse: 1657.8954\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 56.8211 - mse: 5441.4578\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.2909 - mse: 221.1293\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.3304 - mse: 330.0120\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8145 - mse: 215.9797\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4721 - mse: 95.5154\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.6526 - mse: 404.8040\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4634 - mse: 169.1310\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.7760 - mse: 459.8314\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.1198 - mse: 569.0893\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.4944 - mse: 654.6215\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5667 - mse: 268.1430\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2999 - mse: 188.8544\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1115 - mse: 175.7055\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5895 - mse: 869.7923\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9461 - mse: 113.3929\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0273 - mse: 188.4640\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0557 - mse: 132.7936\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8711 - mse: 427.6238\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5485 - mse: 96.8224\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7912 - mse: 256.8746\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2969 - mse: 145.4000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.1753 - mse: 1732.7588\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1257 - mse: 300.5092\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.3921 - mse: 897.0253\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.5967 - mse: 834.7571\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0101 - mse: 137.5419\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4333 - mse: 186.3946\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4491 - mse: 96.3009\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6438 - mse: 218.5184\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3168 - mse: 208.3239\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1832 - mse: 422.8597\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.4860 - mse: 128.6800\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8072 - mse: 160.7222\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2892 - mse: 945.1685\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7923 - mse: 145.3387\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.0328 - mse: 725.3462\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.6505 - mse: 132.1476\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8455 - mse: 155.3464\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0960 - mse: 770.1602\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7402 - mse: 139.4087\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8968 - mse: 339.6098\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.7092 - mse: 66.6670\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6475 - mse: 146.9912\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.6152 - mse: 948.2740\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7602 - mse: 119.7264\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.9799 - mse: 172.5533\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6488 - mse: 432.3298\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.2784 - mse: 98.6556\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.4604 - mse: 902.0727\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 27.4405 - mse: 1158.6084\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7139 - mse: 170.4368\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6757 - mse: 196.1245\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9045 - mse: 414.3998\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0376 - mse: 70.0240\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1558 - mse: 321.1297\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1583 - mse: 311.4818\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.8683 - mse: 554.4750\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.7657 - mse: 1357.5454\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7059 - mse: 108.4962\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.5531 - mse: 674.2966\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5827 - mse: 128.0419\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.2158 - mse: 463.7713\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1935 - mse: 75.5075\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4261 - mse: 438.1330\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1722 - mse: 164.3355\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.9207 - mse: 491.7021\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2012 - mse: 208.9877\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2931 - mse: 158.5947\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.4562 - mse: 254.5623\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.1754 - mse: 612.1691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb00fee4710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "RW1hakVSCOUg",
        "outputId": "1561f30b-5a2e-4b42-db19-d5608ab490cb"
      },
      "source": [
        "# Make and plot predictions of model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb00ff008c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgQMdpCICc9Q",
        "outputId": "ab4f5a7c-8d24-4756-bab1-9dbbb9ba27b0"
      },
      "source": [
        "# Calculate model_2 evaluation metrics\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "mae_2, mse_2"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frsg7iYgCvo8"
      },
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "* 2 layers, trained for 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sfbKhNdDCXn",
        "outputId": "a3bd0102-d41f-41c4-e1b5-cd6dc7ee2333"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.8627 - mae: 26.8627\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.4175 - mae: 24.4175\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.5187 - mae: 31.5187\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.8490 - mae: 27.8490\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.6465 - mae: 14.6465\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.9682 - mae: 11.9682\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0874 - mae: 11.0874\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.3978 - mae: 11.3978\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 42.4087 - mae: 42.4087\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.3537 - mae: 28.3537\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6590 - mae: 9.6590\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.8820 - mae: 25.8820\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.7682 - mae: 16.7682\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.6019 - mae: 26.6019\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7361 - mae: 17.7361\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4550 - mae: 7.4550\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6974 - mae: 10.6974\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.7691 - mae: 20.7691\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6535 - mae: 9.6535\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4600 - mae: 18.4600\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.2352 - mae: 16.2352\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5012 - mae: 14.5012\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6493 - mae: 8.6493\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4430 - mae: 10.4430\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.8060 - mae: 12.8060\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.8011 - mae: 26.8011\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0333 - mae: 12.0333\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.4573 - mae: 23.4573\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1266 - mae: 9.1266\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.1804 - mae: 31.1804\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 56.8211 - mae: 56.8211\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2909 - mae: 12.2909\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.3304 - mae: 15.3304\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.8145 - mae: 12.8145\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4721 - mae: 9.4721\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6526 - mae: 16.6526\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4634 - mae: 10.4634\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.7760 - mae: 18.7760\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.1198 - mae: 20.1198\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.4944 - mae: 21.4944\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5667 - mae: 14.5667\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2999 - mae: 12.2999\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.1115 - mae: 11.1115\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.5895 - mae: 23.5895\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9461 - mae: 9.9461\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0273 - mae: 12.0273\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0557 - mae: 9.0557\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8711 - mae: 17.8711\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5485 - mae: 9.5485\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7912 - mae: 13.7912\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2969 - mae: 11.2969\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.1753 - mae: 32.1753\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1257 - mae: 14.1257\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.3921 - mae: 24.3921\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.5967 - mae: 23.5967\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0101 - mae: 10.0101\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4333 - mae: 12.4333\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4491 - mae: 9.4491\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.6438 - mae: 12.6438\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3168 - mae: 12.3168\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.1832 - mae: 17.1832\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.4860 - mae: 10.4860\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.8072 - mae: 10.8072\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.2892 - mae: 25.2892\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7923 - mae: 10.7923\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.0328 - mae: 22.0328\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6505 - mae: 10.6505\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8455 - mae: 10.8455\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0960 - mae: 23.0960\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7402 - mae: 8.7402\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8968 - mae: 15.8968\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.7092 - mae: 6.7092\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6475 - mae: 10.6475\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.6152 - mae: 24.6152\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7602 - mae: 8.7602\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9799 - mae: 11.9799\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6488 - mae: 16.6488\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2784 - mae: 9.2784\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.4604 - mae: 24.4604\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.4405 - mae: 27.4405\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7139 - mae: 11.7139\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6757 - mae: 11.6757\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9045 - mae: 17.9045\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0376 - mae: 7.0376\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1558 - mae: 15.1558\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1583 - mae: 15.1583\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.8683 - mae: 19.8683\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.7657 - mae: 30.7657\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7059 - mae: 9.7059\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5531 - mae: 21.5531\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5827 - mae: 9.5827\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.2158 - mae: 18.2158\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1935 - mae: 7.1935\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4261 - mae: 17.4261\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1722 - mae: 11.1722\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.9207 - mae: 18.9207\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2012 - mae: 12.2012\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2931 - mae: 11.2931\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.4562 - mae: 13.4562\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.1754 - mae: 20.1754\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4395 - mae: 11.4395\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0888 - mae: 17.0888\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.9455 - mae: 6.9455\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.3779 - mae: 24.3779\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.8800 - mae: 16.8800\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5557 - mae: 8.5557\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.5426 - mae: 26.5426\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.2375 - mae: 13.2375\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1284 - mae: 9.1284\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9256 - mae: 8.9256\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.0550 - mae: 14.0550\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7418 - mae: 9.7418\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.5151 - mae: 17.5151\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0304 - mae: 17.0304\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9228 - mae: 10.9228\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.5453 - mae: 23.5453\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8340 - mae: 8.8340\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2978 - mae: 10.2978\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3192 - mae: 8.3192\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.7265 - mae: 30.7265\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1436 - mae: 8.1436\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.4327 - mae: 29.4327\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.2183 - mae: 34.2183\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.6697 - mae: 19.6697\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5959 - mae: 6.5959\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.8683 - mae: 21.8683\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0892 - mae: 8.0892\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1329 - mae: 21.1329\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3481 - mae: 9.3481\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.2633 - mae: 24.2633\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9302 - mae: 9.9302\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3634 - mae: 18.3634\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2677 - mae: 7.2677\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4166 - mae: 18.4166\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7401 - mae: 9.7401\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8516 - mae: 17.8516\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.9936 - mae: 22.9936\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2013 - mae: 8.2013\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0097 - mae: 8.0097\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9624 - mae: 15.9624\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6422 - mae: 8.6422\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 39.2127 - mae: 39.2127\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9599 - mae: 25.9599\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.6134 - mae: 8.6134\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.7680 - mae: 27.7680\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3428 - mae: 8.3428\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0730 - mae: 15.0730\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.1933 - mae: 19.1933\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4993 - mae: 7.4993\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4097 - mae: 7.4097\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.1762 - mae: 18.1762\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9065 - mae: 9.9065\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.6868 - mae: 30.6868\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6497 - mae: 9.6497\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.0886 - mae: 16.0886\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.0462 - mae: 18.0462\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.4868 - mae: 34.4868\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3002 - mae: 10.3002\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5288 - mae: 8.5288\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.2562 - mae: 22.2562\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.2986 - mae: 11.2986\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 21.5576 - mae: 21.5576\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.8924 - mae: 18.8924\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9458 - mae: 10.9458\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7489 - mae: 8.7489\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.6552 - mae: 22.6552\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.9724 - mae: 26.9724\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2709 - mae: 9.2709\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.1678 - mae: 23.1678\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3051 - mae: 9.3051\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.9237 - mae: 18.9237\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.9900 - mae: 29.9900\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.4918 - mae: 16.4918\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2796 - mae: 10.2796\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.8074 - mae: 28.8074\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1042 - mae: 8.1042\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8722 - mae: 8.8722\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8721 - mae: 17.8721\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4428 - mae: 10.4428\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2716 - mae: 7.2716\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0166 - mae: 17.0166\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3910 - mae: 10.3910\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1568 - mae: 11.1568\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 31.6483 - mae: 31.6483\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0154 - mae: 7.0154\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6843 - mae: 16.6843\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1126 - mae: 8.1126\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.6995 - mae: 29.6995\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3776 - mae: 12.3776\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.3024 - mae: 19.3024\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.9023 - mae: 13.9023\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.9345 - mae: 12.9345\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.5007 - mae: 29.5007\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6526 - mae: 6.6526\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.6620 - mae: 6.6620\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.8540 - mae: 22.8540\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.7492 - mae: 20.7492\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8978 - mae: 11.8978\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.4222 - mae: 17.4222\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.4876 - mae: 13.4876\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.6035 - mae: 5.6035\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.1062 - mae: 13.1062\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4001 - mae: 8.4001\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.0158 - mae: 21.0158\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7459 - mae: 8.7459\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0638 - mae: 11.0638\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.8665 - mae: 13.8665\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.9839 - mae: 13.9839\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.2824 - mae: 14.2824\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.6257 - mae: 17.6257\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.8540 - mae: 8.8540\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.6211 - mae: 18.6211\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0631 - mae: 15.0631\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.8075 - mae: 14.8075\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6706 - mae: 24.6706\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8053 - mae: 12.8053\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7938 - mae: 9.7938\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3979 - mae: 12.3979\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0245 - mae: 5.0245\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8297 - mae: 6.8297\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 37.3270 - mae: 37.3270\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 36.7870 - mae: 36.7870\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.3082 - mae: 7.3082\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 15.3583 - mae: 15.3583\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9646 - mae: 16.9646\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.5040 - mae: 16.5040\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.8008 - mae: 16.8008\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.3646 - mae: 14.3646\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.9498 - mae: 18.9498\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.3734 - mae: 15.3734\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 22.2855 - mae: 22.2855\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.6766 - mae: 25.6766\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8456 - mae: 15.8456\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1198 - mae: 7.1198\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.5359 - mae: 16.5359\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.8411 - mae: 6.8411\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4978 - mae: 8.4978\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6219 - mae: 7.6219\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6738 - mae: 16.6738\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1090 - mae: 8.1090\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2173 - mae: 12.2173\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4286 - mae: 8.4286\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.0474 - mae: 19.0474\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8906 - mae: 13.8906\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9766 - mae: 14.9766\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.5221 - mae: 16.5221\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3671 - mae: 18.3671\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7968 - mae: 12.7968\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.6663 - mae: 14.6663\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.6626 - mae: 24.6626\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8291 - mae: 8.8291\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.5683 - mae: 38.5683\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.8404 - mae: 21.8404\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.6485 - mae: 6.6485\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.9959 - mae: 24.9959\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.5965 - mae: 11.5965\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0635 - mae: 10.0635\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8021 - mae: 13.8021\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3765 - mae: 8.3765\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 45.7482 - mae: 45.7482\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.1356 - mae: 18.1356\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3169 - mae: 6.3169\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.7268 - mae: 13.7268\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.1387 - mae: 22.1387\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.3151 - mae: 19.3151\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9408 - mae: 10.9408\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7507 - mae: 6.7507\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 22.1636 - mae: 22.1636\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 34.7302 - mae: 34.7302\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6729 - mae: 9.6729\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.5267 - mae: 10.5267\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 26.9760 - mae: 26.9760\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.6137 - mae: 11.6137\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.0721 - mae: 12.0721\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.5160 - mae: 30.5160\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.5488 - mae: 6.5488\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 31.9636 - mae: 31.9636\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.5564 - mae: 11.5564\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.3607 - mae: 17.3607\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1189 - mae: 23.1189\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.5078 - mae: 22.5078\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.2141 - mae: 7.2141\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7725 - mae: 7.7725\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.4832 - mae: 25.4832\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.3877 - mae: 13.3877\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2528 - mae: 6.2528\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.2020 - mae: 25.2020\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.5697 - mae: 20.5697\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0906 - mae: 11.0906\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.0029 - mae: 17.0029\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.6342 - mae: 17.6342\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1010 - mae: 8.1010\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.5974 - mae: 15.5974\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.0056 - mae: 24.0056\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.6288 - mae: 17.6288\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7207 - mae: 5.7207\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.5090 - mae: 9.5090\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.2070 - mae: 24.2070\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.5093 - mae: 17.5093\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.9937 - mae: 6.9937\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.4316 - mae: 25.4316\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.5327 - mae: 8.5327\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.2889 - mae: 17.2889\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1101 - mae: 10.1101\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0683 - mae: 12.0683\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9177 - mae: 7.9177\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7052 - mae: 12.7052\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.9439 - mae: 6.9439\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8822 - mae: 8.8822\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3575 - mae: 10.3575\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4583 - mae: 12.4583\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.1003 - mae: 30.1003\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.8146 - mae: 6.8146\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5820 - mae: 8.5820\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.8169 - mae: 24.8169\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.7743 - mae: 15.7743\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.6639 - mae: 20.6639\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6411 - mae: 7.6411\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.5017 - mae: 17.5017\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6369 - mae: 9.6369\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6257 - mae: 7.6257\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.7523 - mae: 4.7523\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.8769 - mae: 23.8769\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.5827 - mae: 6.5827\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.7011 - mae: 15.7011\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0888 - mae: 7.0888\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.2157 - mae: 20.2157\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8279 - mae: 13.8279\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7642 - mae: 17.7642\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.3600 - mae: 6.3600\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7519 - mae: 21.7519\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2420 - mae: 11.2420\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1790 - mae: 11.1790\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5349 - mae: 7.5349\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1596 - mae: 11.1596\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.2226 - mae: 32.2226\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5676 - mae: 9.5676\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4626 - mae: 20.4626\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 36.5697 - mae: 36.5697\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4412 - mae: 9.4412\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.2981 - mae: 9.2981\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7808 - mae: 11.7808\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6574 - mae: 8.6574\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2876 - mae: 5.2876\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 39.5019 - mae: 39.5019\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.1694 - mae: 16.1694\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.1609 - mae: 12.1609\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.1087 - mae: 7.1087\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.9491 - mae: 12.9491\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 16.1665 - mae: 16.1665\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.0546 - mae: 34.0546\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2398 - mae: 14.2398\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6958 - mae: 16.6958\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.8495 - mae: 19.8495\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 35.6263 - mae: 35.6263\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3612 - mae: 7.3612\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.8732 - mae: 25.8732\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.0121 - mae: 23.0121\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5922 - mae: 7.5922\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.7494 - mae: 22.7494\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.6563 - mae: 20.6563\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.4755 - mae: 6.4755\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.4405 - mae: 26.4405\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 33.4598 - mae: 33.4598\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3624 - mae: 9.3624\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.1176 - mae: 8.1176\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.5796 - mae: 31.5796\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3113 - mae: 9.3113\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4731 - mae: 15.4731\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.1064 - mae: 15.1064\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.6474 - mae: 24.6474\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0766 - mae: 12.0766\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6626 - mae: 8.6626\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5077 - mae: 8.5077\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7401 - mae: 12.7401\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4849 - mae: 15.4849\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3770 - mae: 14.3770\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.3350 - mae: 17.3350\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5410 - mae: 21.5410\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 35.0745 - mae: 35.0745\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6949 - mae: 7.6949\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5581 - mae: 12.5581\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7018 - mae: 7.7018\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5894 - mae: 6.5894\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5069 - mae: 9.5069\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.0157 - mae: 21.0157\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.3279 - mae: 25.3279\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1201 - mae: 8.1201\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.9262 - mae: 5.9262\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.9399 - mae: 24.9399\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3383 - mae: 5.3383\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4748 - mae: 15.4748\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.3155 - mae: 5.3155\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0902 - mae: 10.0902\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.1821 - mae: 14.1821\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8618 - mae: 6.8618\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0388 - mae: 8.0388\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 13.8073 - mae: 13.8073\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.7530 - mae: 9.7530\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.2993 - mae: 23.2993\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.3730 - mae: 14.3730\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7284 - mae: 7.7284\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4205 - mae: 9.4205\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.3544 - mae: 9.3544\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.8138 - mae: 5.8138\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.3152 - mae: 17.3152\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8933 - mae: 9.8933\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.8613 - mae: 21.8613\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.9579 - mae: 32.9579\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9618 - mae: 7.9618\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.7364 - mae: 14.7364\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1980 - mae: 23.1980\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8724 - mae: 11.8724\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3169 - mae: 5.3169\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.9845 - mae: 12.9845\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.9657 - mae: 27.9657\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0398 - mae: 10.0398\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4292 - mae: 12.4292\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.7570 - mae: 16.7570\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.5950 - mae: 25.5950\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.8935 - mae: 16.8935\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5194 - mae: 6.5194\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.2627 - mae: 26.2627\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3894 - mae: 14.3894\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.5461 - mae: 6.5461\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 20.0221 - mae: 20.0221\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4675 - mae: 5.4675\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9020 - mae: 11.9020\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7413 - mae: 9.7413\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3967 - mae: 10.3967\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5247 - mae: 9.5247\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4026 - mae: 10.4026\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5572 - mae: 9.5572\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.0641 - mae: 31.0641\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7320 - mae: 8.7320\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.4039 - mae: 30.4039\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2410 - mae: 7.2410\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4983 - mae: 11.4983\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.0209 - mae: 34.0209\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0207 - mae: 15.0207\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.6827 - mae: 18.6827\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.3211 - mae: 23.3211\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.7391 - mae: 23.7391\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.5044 - mae: 10.5044\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.2148 - mae: 15.2148\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.1407 - mae: 19.1407\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.9130 - mae: 4.9130\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6091 - mae: 8.6091\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.8472 - mae: 13.8472\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7478 - mae: 17.7478\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.7603 - mae: 14.7603\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 31.1154 - mae: 31.1154\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3488 - mae: 6.3488\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 28.8322 - mae: 28.8322\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3912 - mae: 7.3912\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8416 - mae: 8.8416\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4993 - mae: 15.4993\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7243 - mae: 17.7243\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.5770 - mae: 27.5770\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7501 - mae: 11.7501\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.5889 - mae: 11.5889\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.2257 - mae: 13.2257\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.3476 - mae: 30.3476\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3242 - mae: 3.3242\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.9370 - mae: 15.9370\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.7724 - mae: 21.7724\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.6820 - mae: 31.6820\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6243 - mae: 9.6243\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8263 - mae: 11.8263\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2032 - mae: 3.2032\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.3217 - mae: 17.3217\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.9616 - mae: 12.9616\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3344 - mae: 16.3344\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4298 - mae: 10.4298\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.3095 - mae: 17.3095\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.0110 - mae: 14.0110\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 31.3851 - mae: 31.3851\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4666 - mae: 7.4666\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3610 - mae: 9.3610\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.0261 - mae: 19.0261\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.5661 - mae: 16.5661\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.2981 - mae: 22.2981\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 25.8888 - mae: 25.8888\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0995 - mae: 24.0995\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2883 - mae: 5.2883\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.4084 - mae: 20.4084\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.3825 - mae: 14.3825\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 32.0213 - mae: 32.0213\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1841 - mae: 11.1841\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.9448 - mae: 11.9448\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.6860 - mae: 24.6860\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3409 - mae: 20.3409\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.5806 - mae: 4.5806\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1887 - mae: 12.1887\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.4238 - mae: 13.4238\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0397 - mae: 12.0397\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.8880 - mae: 18.8880\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.8076 - mae: 23.8076\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9942 - mae: 8.9942\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.1579 - mae: 15.1579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb00fd467d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "Fem6mBsnDUdS",
        "outputId": "82550019-e35d-4c8c-e96b-936280ac0272"
      },
      "source": [
        "# Make and plot some predictions\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb00fdc0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSmrikFDpE8",
        "outputId": "f1fac384-15ac-40e2-ad14-b741e0d30335"
      },
      "source": [
        "# Calculate model_3 evalaution metrics\n",
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3 = mse(y_test, y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwtZ03YGSdv"
      },
      "source": [
        " **Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_5UdQMOEA5y"
      },
      "source": [
        "### Comparing the results of our experiments\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "OZe_HWXzESJ8",
        "outputId": "b71809d8-73fe-4f31-dabd-4f1f00274a55"
      },
      "source": [
        "# Let's compare our model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OTx1UNfHVKZ"
      },
      "source": [
        "Looks like `model_2` performed the best..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhFEXF1iG665",
        "outputId": "84745532-3e47-487a-8b38-24e486df8263"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaa6e-HMHILL"
      },
      "source": [
        ">  **Note:** One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practioner's motto: \"experiment, experiment, experiment\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DI9I7j3H1-r"
      },
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you're running lots of experiments.\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        " **Resource:** As you build more models, you'll want to look into using:\n",
        "\n",
        "* [TensorBoard](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments (we'll see this one later).\n",
        "* [Weights & Biases](https://www.wandb.com/) - a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3fF957RIrwz"
      },
      "source": [
        "## Saving our models\n",
        "\n",
        "Saving our models allows us to use them outside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
        "\n",
        "There are two main formats we can save our model's too:\n",
        "\n",
        "1. The SavedModel format\n",
        "2. The HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFPevKYiIxRl",
        "outputId": "ffaf37da-fe3b-4a1d-8444-ab3f12d227b6"
      },
      "source": [
        "# Save model using the SavedModel format\n",
        "model_2.save(\"best_model_SavedModel_format\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xg2mFS9s4eA"
      },
      "source": [
        "# Save model using the HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMTu6_fStqIQ"
      },
      "source": [
        "## Loading in a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-mCdNXLuUbV",
        "outputId": "24af5395-2d7b-4bb1-fd2e-f09b451d5851"
      },
      "source": [
        "# Load in the SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
        "loaded_SavedModel_format.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13H-0FV5utDN",
        "outputId": "94d79458-032f-4645-e0e2-e8ae1a89319e"
      },
      "source": [
        "# Compare model_2 predictions with SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb00fbb0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyATYIrLuxrM",
        "outputId": "bfee0f13-b967-46db-ca45-dc0dc5372d42"
      },
      "source": [
        "# Compare the MAE of model_2 preds and loaded_SavedModel_preds\n",
        "mae(y_true=y_test, y_pred=model_2_preds) == mae(y_true=y_test, y_pred=loaded_SavedModel_format_preds)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYRN_QQ1v36P",
        "outputId": "7fce4c36-4bec-44c7-ed63-fa4c5791660c"
      },
      "source": [
        "# Load in a model using the .h5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"/content/best_model_HDF5_format.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tAE0IE7wHWz",
        "outputId": "112839ea-108a-4cbb-f4b9-617221ba81f7"
      },
      "source": [
        "# Check to see if loaded .h5 model predictions match model_2\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "model_2_preds == loaded_h5_model_preds"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb00fc6ce60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFnorbpwon_"
      },
      "source": [
        "## Download a model (or any other file) from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to the \"files\" tab and right click on the file you're after and click \"download\".\n",
        "2. Use code (see the cell below).\n",
        "3. Save it to Google Drive by connecting Google Drive and copying it there (see 2nd code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MrfvCrjgxSg2",
        "outputId": "2585300e-4dbf-471e-90c8-f3d6a52b3386"
      },
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_HDF5_format.h5\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c111bcb7-b613-4ef3-b0d9-a06b8bf7c24f\", \"best_model_HDF5_format.h5\", 16952)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eQEQSJ8xypc"
      },
      "source": [
        "# Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
        "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/tensorflow_course"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ODwgyDRyaBh",
        "outputId": "c3d45bf7-156c-4496-c201-2e75fed8073a"
      },
      "source": [
        "!ls /content/drive/MyDrive/tensorflow_course"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101_food_class_10_percent_saved_big_dog_model  food_vision\n",
            "10_food_classes_model_5_epochs\t\t       skim_lit\n",
            "best_model_HDF5_format.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-Yv-2Bhymy6"
      },
      "source": [
        "## A larger example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vZ8AIbD1XpM"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "uPQmsO6Y2Exv",
        "outputId": "e0d8e59e-8e2f-479c-ab72-a9a6fd6b01a2"
      },
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "robZtd8l2y19",
        "outputId": "5442a4e0-aaf0-42aa-c280-e20f6bfb1cb3"
      },
      "source": [
        "# Let's try one-hot encode our DataFrame so it's all numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGU53qHw3yTQ"
      },
      "source": [
        "# Create X & y values (features and labels)\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "879Oxm4Z5I9H",
        "outputId": "22e9d1cc-b9fa-4f12-f8a9-25e4a9d99b48"
      },
      "source": [
        "# View X\n",
        "X.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkDW7YGa5MNu",
        "outputId": "59e1b2e2-0a39-4ef5-9a36-346aed89c1a7"
      },
      "source": [
        "# View y\n",
        "y.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a1cIygD46Ng",
        "outputId": "5e33f50f-058d-437f-ea9c-a9de0dc1d90c"
      },
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "len(X), len(X_train), len(X_test)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6A8y4WT47s4",
        "outputId": "735ea887-f583-4d9d-cf45-52e6343eea76"
      },
      "source": [
        "# Build a neural network (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 10200.7270 - mae: 10200.7270\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7718.1918 - mae: 7718.1918\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6983.7825 - mae: 6983.7825\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 977us/step - loss: 8083.4823 - mae: 8083.4823\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7793.8446 - mae: 7793.8446\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7618.4114 - mae: 7618.4114\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7678.4982 - mae: 7678.4982\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.4293 - mae: 7780.4293\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7588.8131 - mae: 7588.8131\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 977us/step - loss: 7520.6834 - mae: 7520.6834\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8309.7824 - mae: 8309.7824\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.0188 - mae: 7748.0188\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7888.3570 - mae: 7888.3570\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7731.1156 - mae: 7731.1156\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7786.1046 - mae: 7786.1046\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8343.8844 - mae: 8343.8844\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7142.3614 - mae: 7142.3614\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 966us/step - loss: 8070.0514 - mae: 8070.0514\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7604.8299 - mae: 7604.8299\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7945.1275 - mae: 7945.1275\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6864.6826 - mae: 6864.6826\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 975us/step - loss: 7505.7917 - mae: 7505.7917\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7621.7373 - mae: 7621.7373\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7262.7541 - mae: 7262.7541\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8156.1950 - mae: 8156.1950\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7246.2713 - mae: 7246.2713\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7562.7819 - mae: 7562.7819\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7842.6208 - mae: 7842.6208\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7153.8771 - mae: 7153.8771\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7723.4958 - mae: 7723.4958\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8310.0626 - mae: 8310.0626\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7734.9659 - mae: 7734.9659\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.4657 - mae: 7403.4657\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7482.6286 - mae: 7482.6286\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7198.8918 - mae: 7198.8918\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.1018 - mae: 7484.1018\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7701.6282 - mae: 7701.6282\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6923.6147 - mae: 6923.6147\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7673.7908 - mae: 7673.7908\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 971us/step - loss: 7670.9196 - mae: 7670.9196\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7774.5879 - mae: 7774.5879\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7413.0881 - mae: 7413.0881\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7793.8666 - mae: 7793.8666\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7239.3580 - mae: 7239.3580\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7402.6568 - mae: 7402.6568\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7167.7288 - mae: 7167.7288\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7716.9021 - mae: 7716.9021\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7509.9137 - mae: 7509.9137\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7216.6765 - mae: 7216.6765\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7354.2574 - mae: 7354.2574\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7587.3343 - mae: 7587.3343\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7697.7624 - mae: 7697.7624\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.7633 - mae: 7084.7633\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 988us/step - loss: 7366.1161 - mae: 7366.1161\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7354.5008 - mae: 7354.5008\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7201.4707 - mae: 7201.4707\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7612.1702 - mae: 7612.1702\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7684.3348 - mae: 7684.3348\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7315.3648 - mae: 7315.3648\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7381.6660 - mae: 7381.6660\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7842.5246 - mae: 7842.5246\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7346.2639 - mae: 7346.2639\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7634.5373 - mae: 7634.5373\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6976.2137 - mae: 6976.2137\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7608.7969 - mae: 7608.7969\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.7901 - mae: 7275.7901\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7244.1644 - mae: 7244.1644\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7553.0944 - mae: 7553.0944\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8028.1965 - mae: 8028.1965\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7150.7140 - mae: 7150.7140\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.5194 - mae: 7137.5194\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 975us/step - loss: 6708.9289 - mae: 6708.9289\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7554.2732 - mae: 7554.2732\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7060.4082 - mae: 7060.4082\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7564.8154 - mae: 7564.8154\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7016.7824 - mae: 7016.7824\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7936.9771 - mae: 7936.9771\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6828.1385 - mae: 6828.1385\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6875.0803 - mae: 6875.0803\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6770.6309 - mae: 6770.6309\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7216.2089 - mae: 7216.2089\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7774.2737 - mae: 7774.2737\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7156.2561 - mae: 7156.2561\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7436.0038 - mae: 7436.0038\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6855.7935 - mae: 6855.7935\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7768.8272 - mae: 7768.8272\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7014.5803 - mae: 7014.5803\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7525.7779 - mae: 7525.7779\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6994.6074 - mae: 6994.6074\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7677.9609 - mae: 7677.9609\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7210.0508 - mae: 7210.0508\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.2229 - mae: 7335.2229\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7235.0912 - mae: 7235.0912\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6728.8875 - mae: 6728.8875\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7811.5180 - mae: 7811.5180\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7430.2757 - mae: 7430.2757\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6876.5980 - mae: 6876.5980\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7070.8702 - mae: 7070.8702\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7118.6878 - mae: 7118.6878\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6880.6746 - mae: 6880.6746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0031c5e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmRjvYMu6Yeu",
        "outputId": "111b0376-a856-4153-aa9e-fd8a7c25b87e"
      },
      "source": [
        "# Check the results of the insurance model on the test data\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u1tPVZu7bx9",
        "outputId": "5ef0dfc4-853c-4fc2-c91c-e1f13c21fa2b"
      },
      "source": [
        "y_train.median(), y_train.mean()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364489)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEMaHr1m7j9n"
      },
      "source": [
        "Right now it looks like our model isn't performing too well... let's try and improve it!\n",
        "\n",
        "To (try) improve our model, we'll run 2 experiments:\n",
        "1. Add an extra layer with more hidden units and use the Adam optimizer\n",
        "2. Same as above but train for longer (200 epochs)\n",
        "3. (insert your own experiment here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PV6yAHm9dR0",
        "outputId": "18d7ed31-63a3-4aec-bf6c-d20eb564d21f"
      },
      "source": [
        "X_train, y_train"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      age     bmi  ...  region_southeast  region_southwest\n",
              " 560    46  19.950  ...                 0                 0\n",
              " 1285   47  24.320  ...                 0                 0\n",
              " 1142   52  24.860  ...                 1                 0\n",
              " 969    39  34.320  ...                 1                 0\n",
              " 486    54  21.470  ...                 0                 0\n",
              " ...   ...     ...  ...               ...               ...\n",
              " 1095   18  31.350  ...                 0                 0\n",
              " 1130   39  23.870  ...                 1                 0\n",
              " 1294   58  25.175  ...                 0                 0\n",
              " 860    37  47.600  ...                 0                 1\n",
              " 1126   55  29.900  ...                 0                 1\n",
              " \n",
              " [1070 rows x 11 columns], 560      9193.83850\n",
              " 1285     8534.67180\n",
              " 1142    27117.99378\n",
              " 969      8596.82780\n",
              " 486     12475.35130\n",
              "            ...     \n",
              " 1095     4561.18850\n",
              " 1130     8582.30230\n",
              " 1294    11931.12525\n",
              " 860     46113.51100\n",
              " 1126    10214.63600\n",
              " Name: charges, Length: 1070, dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2437V9zH758n",
        "outputId": "c40fd23e-ca53-45b5-a2be-afaa897f01b3"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13251.7400 - mae: 13251.7400\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12768.7726 - mae: 12768.7726\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12248.2855 - mae: 12248.2855\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12353.0241 - mae: 12353.0241\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11243.3972 - mae: 11243.3972\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9718.5257 - mae: 9718.5257\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8354.8474 - mae: 8354.8474\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7732.2963 - mae: 7732.2963\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.6737 - mae: 7537.6737\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7652.7184 - mae: 7652.7184\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7802.4481 - mae: 7802.4481\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7370.3458 - mae: 7370.3458\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7651.9583 - mae: 7651.9583\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7404.5587 - mae: 7404.5587\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.0614 - mae: 7639.0614\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7569.4714 - mae: 7569.4714\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6946.3939 - mae: 6946.3939\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.7239 - mae: 7137.7239\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7165.3120 - mae: 7165.3120\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7063.6223 - mae: 7063.6223\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6472.3188 - mae: 6472.3188\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6674.0546 - mae: 6674.0546\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7112.2982 - mae: 7112.2982\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6838.1523 - mae: 6838.1523\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.9559 - mae: 7496.9559\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6718.1681 - mae: 6718.1681\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7107.2972 - mae: 7107.2972\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7357.2015 - mae: 7357.2015\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6668.5721 - mae: 6668.5721\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7119.4991 - mae: 7119.4991\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7360.1232 - mae: 7360.1232\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6817.2565 - mae: 6817.2565\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6991.0289 - mae: 6991.0289\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6829.4910 - mae: 6829.4910\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6895.2913 - mae: 6895.2913\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6762.5128 - mae: 6762.5128\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6910.4815 - mae: 6910.4815\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6405.0325 - mae: 6405.0325\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6799.7919 - mae: 6799.7919\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6696.0554 - mae: 6696.0554\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6632.0476 - mae: 6632.0476\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6501.1589 - mae: 6501.1589\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6518.8876 - mae: 6518.8876\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6287.3747 - mae: 6287.3747\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6331.2562 - mae: 6331.2562\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6080.3168 - mae: 6080.3168\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6665.8195 - mae: 6665.8195\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6424.2358 - mae: 6424.2358\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6154.8287 - mae: 6154.8287\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6426.9841 - mae: 6426.9841\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6338.3257 - mae: 6338.3257\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6335.6011 - mae: 6335.6011\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5995.7961 - mae: 5995.7961\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6431.7964 - mae: 6431.7964\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6224.0661 - mae: 6224.0661\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6289.4113 - mae: 6289.4113\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6578.3135 - mae: 6578.3135\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6365.6008 - mae: 6365.6008\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5914.7983 - mae: 5914.7983\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6239.8720 - mae: 6239.8720\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6751.6415 - mae: 6751.6415\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6350.5861 - mae: 6350.5861\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6374.7378 - mae: 6374.7378\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5877.7617 - mae: 5877.7617\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6260.5317 - mae: 6260.5317\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6007.1749 - mae: 6007.1749\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6106.7941 - mae: 6106.7941\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6035.6668 - mae: 6035.6668\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6523.5435 - mae: 6523.5435\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5708.9527 - mae: 5708.9527\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6110.2172 - mae: 6110.2172\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5773.3150 - mae: 5773.3150\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6297.5183 - mae: 6297.5183\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6112.9394 - mae: 6112.9394\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6449.7250 - mae: 6449.7250\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5688.1442 - mae: 5688.1442\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6402.3397 - mae: 6402.3397\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5499.5554 - mae: 5499.5554\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5108.3478 - mae: 5108.3478\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5226.6398 - mae: 5226.6398\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5817.3262 - mae: 5817.3262\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6548.7323 - mae: 6548.7323\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5722.6892 - mae: 5722.6892\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5570.2336 - mae: 5570.2336\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5121.8587 - mae: 5121.8587\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5889.9363 - mae: 5889.9363\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5472.2751 - mae: 5472.2751\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5770.0215 - mae: 5770.0215\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5392.7423 - mae: 5392.7423\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5951.3923 - mae: 5951.3923\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5577.1110 - mae: 5577.1110\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5633.8429 - mae: 5633.8429\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5209.0318 - mae: 5209.0318\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5018.4430 - mae: 5018.4430\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5419.2087 - mae: 5419.2087\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5547.8981 - mae: 5547.8981\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4931.7088 - mae: 4931.7088\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4912.5428 - mae: 4912.5428\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4650.0256 - mae: 4650.0256\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4770.1080 - mae: 4770.1080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb05327e990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRqPnfiW9KDy",
        "outputId": "4fe652d8-a62b-449b-a773-0720d345a593"
      },
      "source": [
        "# Evaluate the larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 4924.4956 - mae: 4924.4956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.49560546875, 4924.49560546875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnV2Vsn79Wj1",
        "outputId": "6eae3637-752f-4347-ee0a-b6db1e6466d0"
      },
      "source": [
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 7023.3296 - mae: 7023.3296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.32958984375, 7023.32958984375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKl1-Eir98Si",
        "outputId": "981d2cc0-599a-4067-bcd3-1c60b87729a0"
      },
      "source": [
        "# Set random set\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (same as above)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                                \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13251.7400 - mae: 13251.7400\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12768.7726 - mae: 12768.7726\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12248.2855 - mae: 12248.2855\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12353.0241 - mae: 12353.0241\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11243.3972 - mae: 11243.3972\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9718.5257 - mae: 9718.5257\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8354.8474 - mae: 8354.8474\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7732.2963 - mae: 7732.2963\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.6737 - mae: 7537.6737\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7652.7184 - mae: 7652.7184\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7802.4481 - mae: 7802.4481\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7370.3458 - mae: 7370.3458\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7651.9583 - mae: 7651.9583\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7404.5587 - mae: 7404.5587\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.0614 - mae: 7639.0614\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.4714 - mae: 7569.4714\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6946.3939 - mae: 6946.3939\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.7239 - mae: 7137.7239\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7165.3120 - mae: 7165.3120\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7063.6223 - mae: 7063.6223\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6472.3188 - mae: 6472.3188\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6674.0546 - mae: 6674.0546\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7112.2982 - mae: 7112.2982\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6838.1523 - mae: 6838.1523\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.9559 - mae: 7496.9559\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6718.1681 - mae: 6718.1681\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7107.2972 - mae: 7107.2972\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7357.2015 - mae: 7357.2015\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6668.5721 - mae: 6668.5721\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7119.4991 - mae: 7119.4991\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7360.1232 - mae: 7360.1232\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6817.2565 - mae: 6817.2565\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6991.0289 - mae: 6991.0289\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6829.4910 - mae: 6829.4910\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6895.2913 - mae: 6895.2913\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6762.5128 - mae: 6762.5128\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6910.4815 - mae: 6910.4815\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6405.0325 - mae: 6405.0325\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6799.7919 - mae: 6799.7919\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6696.0554 - mae: 6696.0554\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6632.0476 - mae: 6632.0476\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6501.1589 - mae: 6501.1589\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6518.8876 - mae: 6518.8876\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6287.3747 - mae: 6287.3747\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6331.2562 - mae: 6331.2562\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6080.3168 - mae: 6080.3168\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6665.8195 - mae: 6665.8195\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6424.2358 - mae: 6424.2358\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6154.8287 - mae: 6154.8287\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6426.9841 - mae: 6426.9841\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6338.3257 - mae: 6338.3257\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6335.6011 - mae: 6335.6011\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5995.7961 - mae: 5995.7961\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6431.7964 - mae: 6431.7964\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6224.0661 - mae: 6224.0661\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6289.4113 - mae: 6289.4113\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6578.3135 - mae: 6578.3135\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6365.6008 - mae: 6365.6008\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5914.7983 - mae: 5914.7983\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6239.8720 - mae: 6239.8720\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6751.6415 - mae: 6751.6415\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6350.5861 - mae: 6350.5861\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6374.7378 - mae: 6374.7378\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5877.7617 - mae: 5877.7617\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6260.5317 - mae: 6260.5317\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6007.1749 - mae: 6007.1749\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6106.7941 - mae: 6106.7941\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6035.6668 - mae: 6035.6668\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6523.5435 - mae: 6523.5435\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5708.9527 - mae: 5708.9527\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6110.2172 - mae: 6110.2172\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5773.3150 - mae: 5773.3150\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6297.5183 - mae: 6297.5183\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.9394 - mae: 6112.9394\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6449.7250 - mae: 6449.7250\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5688.1442 - mae: 5688.1442\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6402.3397 - mae: 6402.3397\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5499.5554 - mae: 5499.5554\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5108.3478 - mae: 5108.3478\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5226.6398 - mae: 5226.6398\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5817.3262 - mae: 5817.3262\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6548.7323 - mae: 6548.7323\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5722.6892 - mae: 5722.6892\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5570.2336 - mae: 5570.2336\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5121.8587 - mae: 5121.8587\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5889.9363 - mae: 5889.9363\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5472.2751 - mae: 5472.2751\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5770.0215 - mae: 5770.0215\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5392.7423 - mae: 5392.7423\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5951.3923 - mae: 5951.3923\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5577.1110 - mae: 5577.1110\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5633.8429 - mae: 5633.8429\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5209.0318 - mae: 5209.0318\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5018.4430 - mae: 5018.4430\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5419.2087 - mae: 5419.2087\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5547.8981 - mae: 5547.8981\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4931.7088 - mae: 4931.7088\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4912.5428 - mae: 4912.5428\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4650.0256 - mae: 4650.0256\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4770.1080 - mae: 4770.1080\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4909.4022 - mae: 4909.4022\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4673.1832 - mae: 4673.1832\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4396.6370 - mae: 4396.6370\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4917.2483 - mae: 4917.2483\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4314.7068 - mae: 4314.7068\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4740.0049 - mae: 4740.0049\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4745.8710 - mae: 4745.8710\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4517.0621 - mae: 4517.0621\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4801.7184 - mae: 4801.7184\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4703.4161 - mae: 4703.4161\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4289.2303 - mae: 4289.2303\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4062.2468 - mae: 4062.2468\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3977.3070 - mae: 3977.3070\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4154.2934 - mae: 4154.2934\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4006.4258 - mae: 4006.4258\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4287.0862 - mae: 4287.0862\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3863.7708 - mae: 3863.7708\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3867.4441 - mae: 3867.4441\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3956.8748 - mae: 3956.8748\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4056.2708 - mae: 4056.2708\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4138.5816 - mae: 4138.5816\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3807.1297 - mae: 3807.1297\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3729.3961 - mae: 3729.3961\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.5895 - mae: 3654.5895\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4047.5810 - mae: 4047.5810\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3760.0189 - mae: 3760.0189\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3898.9773 - mae: 3898.9773\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3730.5283 - mae: 3730.5283\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4053.7942 - mae: 4053.7942\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3816.5713 - mae: 3816.5713\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3842.2270 - mae: 3842.2270\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4002.9710 - mae: 4002.9710\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4039.3410 - mae: 4039.3410\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3876.1981 - mae: 3876.1981\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3853.5075 - mae: 3853.5075\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3717.2626 - mae: 3717.2626\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3773.6438 - mae: 3773.6438\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4017.7876 - mae: 4017.7876\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3715.0605 - mae: 3715.0605\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3733.6008 - mae: 3733.6008\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3857.4200 - mae: 3857.4200\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3626.7239 - mae: 3626.7239\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3835.3856 - mae: 3835.3856\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3868.5909 - mae: 3868.5909\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4045.0617 - mae: 4045.0617\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3947.5989 - mae: 3947.5989\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.7624 - mae: 3697.7624\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3495.4071 - mae: 3495.4071\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.6808 - mae: 3636.6808\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3824.7629 - mae: 3824.7629\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3806.7232 - mae: 3806.7232\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3755.5285 - mae: 3755.5285\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3713.7236 - mae: 3713.7236\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3894.6997 - mae: 3894.6997\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3651.7698 - mae: 3651.7698\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3541.6651 - mae: 3541.6651\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3542.1334 - mae: 3542.1334\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3921.3846 - mae: 3921.3846\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3774.7317 - mae: 3774.7317\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3836.3787 - mae: 3836.3787\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3695.4663 - mae: 3695.4663\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3844.5049 - mae: 3844.5049\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3434.5002 - mae: 3434.5002\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3657.7765 - mae: 3657.7765\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.6673 - mae: 3725.6673\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3876.2256 - mae: 3876.2256\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4018.4553 - mae: 4018.4553\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3753.0694 - mae: 3753.0694\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3595.9371 - mae: 3595.9371\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3880.9855 - mae: 3880.9855\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3589.4530 - mae: 3589.4530\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3789.1782 - mae: 3789.1782\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3821.4176 - mae: 3821.4176\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3759.3669 - mae: 3759.3669\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3876.6620 - mae: 3876.6620\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3795.9221 - mae: 3795.9221\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3769.8004 - mae: 3769.8004\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3564.1352 - mae: 3564.1352\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3469.2083 - mae: 3469.2083\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4112.5286 - mae: 4112.5286\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3853.0810 - mae: 3853.0810\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3778.7847 - mae: 3778.7847\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8323 - mae: 3475.8323\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.6772 - mae: 3624.6772\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3491.7384 - mae: 3491.7384\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3825.6738 - mae: 3825.6738\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3890.7275 - mae: 3890.7275\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3917.8414 - mae: 3917.8414\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3450.1743 - mae: 3450.1743\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3790.2072 - mae: 3790.2072\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3901.4243 - mae: 3901.4243\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3675.6297 - mae: 3675.6297\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3766.1259 - mae: 3766.1259\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3870.9854 - mae: 3870.9854\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3423.5101 - mae: 3423.5101\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.1774 - mae: 3567.1774\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3951.1267 - mae: 3951.1267\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3620.5315 - mae: 3620.5315\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3630.1026 - mae: 3630.1026\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3812.3689 - mae: 3812.3689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX918PcL-n8s",
        "outputId": "826d9a27-b7b1-479d-85cf-f3918a3337d1"
      },
      "source": [
        "# Evaluate our third model\n",
        "insurance_model_3.evaluate(X_test, y_test)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3488.7854 - mae: 3488.7856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3488.785400390625, 3488.78564453125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImGrhOUu-w8J",
        "outputId": "61317300-e3ae-4416-84b7-bc6e50175813"
      },
      "source": [
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 7023.3296 - mae: 7023.3296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.32958984375, 7023.32958984375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "5obI_2qh-3Yl",
        "outputId": "d329ff59-5211-4b30-e70c-cb3709126e10"
      },
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifIrgZbp_JBA"
      },
      "source": [
        ">  **Question:** How long should you train for?\n",
        "\n",
        "It depends. Really... it depends on the problem you're working on. However, many people have asked this question before... so TensorFlow has a solution! It's called the [EarlyStopping Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), which is a TensorFlow component you can add to your model to stop training once it stops improving a certain metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19mmj6JTACaR"
      },
      "source": [
        "## Preprocessing data (normalization and standardization)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization.\n",
        "\n",
        "If you're not sure on which to use, you could try both and see which performs better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "A9EZSNF_3MaY",
        "outputId": "3da8d8b2-c0a2-4be4-b7c0-dbde7b42f09c"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataframe\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8VN6GfP4Dsn"
      },
      "source": [
        "To prepare our data, we can borrow a few classes from Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR8i1bHZAV6o"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns between 0 and 1 \n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the column transformer to our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGD73N7651a3",
        "outputId": "66b1dd80-023e-4063-9fe6-564bd526a00b"
      },
      "source": [
        "# What does our data look like now?\n",
        "X_train.loc[0]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQsT3lTJ55qS",
        "outputId": "52080d2f-d0a9-4889-8814-2e37067eb3ba"
      },
      "source": [
        "X_train_normal[0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tiE2Dj86M6g",
        "outputId": "97987c42-72b7-4cc5-b2d2-37dc69df9c03"
      },
      "source": [
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7o1A7kL6Yrm"
      },
      "source": [
        "Beautiful! Our data has been normalized and one hot encoded. Now let's build a neural network model on it and see how it goes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDF9TU0_6W2r",
        "outputId": "68c4965f-d307-4461-94cd-866977c86fe2"
      },
      "source": [
        "# Build a neural network model to fit on our normalized data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                                        \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13296.4671 - mae: 13296.4671\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12948.4245 - mae: 12948.4245\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12705.2201 - mae: 12705.2201\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13369.7395 - mae: 13369.7395\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13230.8567 - mae: 13230.8567\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12995.1999 - mae: 12995.1999\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12876.1059 - mae: 12876.1059\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13004.0395 - mae: 13004.0395\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12508.0465 - mae: 12508.0465\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12304.9941 - mae: 12304.9941\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12190.6080 - mae: 12190.6080\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10948.1234 - mae: 10948.1234\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11033.2710 - mae: 11033.2710\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 10209.3786 - mae: 10209.3786\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9943.5373 - mae: 9943.5373\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9393.3773 - mae: 9393.3773\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8554.0272 - mae: 8554.0272\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8463.0882 - mae: 8463.0882\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8238.9920 - mae: 8238.9920\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7992.1423 - mae: 7992.1423\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7246.4886 - mae: 7246.4886\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7520.6745 - mae: 7520.6745\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7862.2003 - mae: 7862.2003\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7617.0075 - mae: 7617.0075\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8118.1866 - mae: 8118.1866\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7381.5776 - mae: 7381.5776\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7759.2990 - mae: 7759.2990\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7961.3147 - mae: 7961.3147\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7357.1594 - mae: 7357.1594\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7670.5822 - mae: 7670.5822\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7833.2163 - mae: 7833.2163\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7408.4352 - mae: 7408.4352\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7603.6621 - mae: 7603.6621\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7385.2735 - mae: 7385.2735\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7340.4551 - mae: 7340.4551\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7276.7011 - mae: 7276.7011\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7342.1807 - mae: 7342.1807\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6918.2723 - mae: 6918.2723\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7252.1239 - mae: 7252.1239\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7029.9498 - mae: 7029.9498\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6984.8117 - mae: 6984.8117\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.6927 - mae: 6884.6927\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.5831 - mae: 6755.5831\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6608.4541 - mae: 6608.4541\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6537.6250 - mae: 6537.6250\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6454.2749 - mae: 6454.2749\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6729.0266 - mae: 6729.0266\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6517.0466 - mae: 6517.0466\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6209.9379 - mae: 6209.9379\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6433.2527 - mae: 6433.2527\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6253.4749 - mae: 6253.4749\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6122.7598 - mae: 6122.7598\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5797.8438 - mae: 5797.8438\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6036.6884 - mae: 6036.6884\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5688.6432 - mae: 5688.6432\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5664.2595 - mae: 5664.2595\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5857.4062 - mae: 5857.4062\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5509.3850 - mae: 5509.3850\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5316.6016 - mae: 5316.6016\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5322.8675 - mae: 5322.8675\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5458.1975 - mae: 5458.1975\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5230.6233 - mae: 5230.6233\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5084.5995 - mae: 5084.5995\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4677.8217 - mae: 4677.8217\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4707.1107 - mae: 4707.1107\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4361.7456 - mae: 4361.7456\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4333.7880 - mae: 4333.7880\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4294.6888 - mae: 4294.6888\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4365.7154 - mae: 4365.7154\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3931.4922 - mae: 3931.4922\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4040.8877 - mae: 4040.8877\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3725.7780 - mae: 3725.7780\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4041.0183 - mae: 4041.0183\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3849.4077 - mae: 3849.4077\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4063.8180 - mae: 4063.8180\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.6085 - mae: 3594.6085\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3877.1157 - mae: 3877.1157\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3571.6357 - mae: 3571.6357\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3272.2002 - mae: 3272.2002\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3333.3793 - mae: 3333.3793\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3560.1417 - mae: 3560.1417\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4082.1635 - mae: 4082.1635\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3690.6047 - mae: 3690.6047\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3491.1416 - mae: 3491.1416\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3196.7646 - mae: 3196.7646\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3696.4113 - mae: 3696.4113\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3584.8876 - mae: 3584.8876\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3717.8066 - mae: 3717.8066\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3437.4365 - mae: 3437.4365\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3799.4694 - mae: 3799.4694\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.1355 - mae: 3660.1355\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3743.4219 - mae: 3743.4219\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3536.3569 - mae: 3536.3569\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3439.5847 - mae: 3439.5847\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.7318 - mae: 3570.7318\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3734.5115 - mae: 3734.5115\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3444.5728 - mae: 3444.5728\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3465.0855 - mae: 3465.0855\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3225.0304 - mae: 3225.0304\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3421.0636 - mae: 3421.0636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb052ec1c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt84g6C790Y0",
        "outputId": "2d3f2b21-b200-4aab-8a5b-5d74654f67b2"
      },
      "source": [
        "# Evalaute our insurance model trained on normalized data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDJuv8gB-IJ0"
      },
      "source": [
        "# Insurance model 2 results\n",
        "# 9/9 [==============================] - 0s 1ms/step - loss: 4924.3477 - mae: 4924.3477"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZZQN7Z5_N46"
      },
      "source": [
        "Our model (`insurance_model_4`) fit on normalized data achieved a ~30% better score compared to the same model (`insurnace_model_2`) fit on non-normalized data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck80C5Im9Qo8",
        "outputId": "7d61c7b6-c3d5-4207-cc1f-5dbebd8f1067"
      },
      "source": [
        "insurance_model_2.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 100)               1200      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,221\n",
            "Trainable params: 2,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}